#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Authors:
# Samuel Läubli <laeubli@cl.uzh.ch>
# Mathias Müller <mmueller@cl.uzh.ch>

import sys
import logging
import argparse


def get_argument_parser():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest='action', help='A simple encoder-'
                                       'decoder machine translation model')
    parser.add_argument('-q', '--quiet', action='store_true',
                        help='No logging output except for warnings and errors.')
    # train
    train = subparsers.add_parser('train', help='Train a machine translation model.')
    train.add_argument('--source', type=str, required=True, dest='source_data',
                       help='the source training data, a tokenized, plain text file.')
    train.add_argument('--target', type=str, required=True, dest='target_data',
                       help='the target training data, a tokenized, plain text file.')
    train.add_argument('-e', '--epochs', type=int, default=10,
                       help='the number of training epochs.')
    train.add_argument('-b', '--batch_size', type=int, default=20)
    train.add_argument('-v', '--vocab_max_size', type=int, default=10000,
                       help='Only keep n most frequent words; treat others as <unk>.')
    train.add_argument('-m', '--save_to', default='model',
                       help='the folder to store model files.')
    train.add_argument('-l', '--log_to', default='logs',
                       help='the folder to store log files. Use for monitoring with tensorboard.')
    train.add_argument('-s', '--sample_after_epoch', default=False, action="store_true",
                       help='Sample translations from the model after each epoch.')

    # translate
    sample = subparsers.add_parser('translate', help='Use a trained model to translate new text.')
    sample.add_argument('-m', '--load_from', default='model',
                        help='the folder to load model and vocabulary files from.')
    sample.add_argument('-i', '--input', type=str, required=False, default=None,
                        help='File that should be translated, one sentence per line.' +
                        ' If omitted, daikon assumes input from STDIN.')
    sample.add_argument('-o', '--output', type=str, required=False, default=None,
                        help='File translations should be written to. If omitted, daikon writes to STDOUT.')

    # score
    score = subparsers.add_parser('score', help='Use a trained model to score parallel text.')
    score.add_argument('-m', '--load_from', default='model',
                       help='the folder to load model and vocabulary files from.')
    score.add_argument('-a', '--corpus_average', default=False, action="store_true",
                       help='Output one single score that is a corpus-level average.')
    score.add_argument('-n', '--normalize', default=False, action="store_true",
                       help='Normalize scores by target sequence length.')
    score.add_argument('--source', type=str, required=True, dest='source_data',
                       help='the source training data, a tokenized, plain text file.')
    score.add_argument('--target', type=str, required=True, dest='target_data',
                       help='the target training data, a tokenized, plain text file.')

    return parser


def action_train(args):
    from daikon.train import train
    train(**vars(args))


def action_score(args):
    from daikon.score import score
    result = score(**vars(args))
    if args.corpus_average:
        print('Perplexity: {0:.2f}'.format(result))
    else:
        result = [str(r) for r in result]
        print("\n".join(result))


def action_translate(args):
    if args.input:
        input_file_handle = open(args.input, "r")
    else:
        logging.info("Argument --input not given, assuming input from STDIN.")
        input_file_handle = sys.stdin

    if args.output:
        output_file_handle = open(args.output, "w")
    else:
        output_file_handle = sys.stdout

    from daikon.translate import translate_file
    translate_file(load_from=args.load_from, input_file_handle=input_file_handle, output_file_handle=output_file_handle)


def main():
    parser = get_argument_parser()
    if len(sys.argv) <= 1:
        parser.print_help()
    args = parser.parse_args()
    # log level
    log_level = logging.WARNING if args.quiet else logging.DEBUG
    logging.basicConfig(level=log_level, format='%(asctime)s - %(levelname)s - %(message)s')
    # delegate
    if args.action == 'train':
        action_train(args)
    elif args.action == 'score':
        action_score(args)
    elif args.action == 'translate':
        action_translate(args)


if __name__ == '__main__':
    main()
